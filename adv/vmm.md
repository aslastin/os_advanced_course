# Менеджер виртуальной памяти (VMM)

## Виртуальная память

- __Логическая концепция.__ 

- __Реализована с помощью физической памяти и VMM.__ Реализация обеспечивается физической памятью, то есть некоторый микросхемой, которая умеет достаточно быстро переключать состояния тех или иных адресуемых элементов (байтов) и адресовать по некоторому линейному индексу. ___VMM (менеджер виртуальной памяти)___ - компонента, обеспечивающая функционирование концепции виртуальной памяти для процесса, ядра.

Виртуальная память существует не только для _userland_ - места, где исполняется пользовательский код. Ядро при загрузке работает с физической памятью, но достаточно быстро включает менеджер виртуальной памяти и тоже начинает работать с виртуальной памятью, только в более высоко приоритетном контексте (режим supervisor). 

- Обеспечивает 
    - __Универсальную вычислительную модель памяти, обычно линейный массив.__ Если мы думаем о логической модели виртуальной памяти, то это разреженный массив от 0 до примерно 2^64, откуда можно получать какие-то значения. В более старых вычислительных системах существовала концепция сегментации, то есть разделение на логические подкомпоненты, в которых адресация происходила 2 частями - _сегментным регистром_, описывающим номер сегмента, и _линейным адресом из сегмента_. От этой концепции отказались, и теперь адрес - это одно число.

     Целью сегментации изначально было разделение адресного пространства на логические единицы. Например, если рассмотреть __x86__, то в нем есть такие регистры как _CS - code segment_ (любой адрес на стеке был неявно вычисляемым относительно стекового сегмента) и _SS - stack segment_(аналогично стековому). Это позволяло более адекватно структурировать программы. Поверх сегментной модели можно строить нетривиальные решения даже в современных системах, позволяющие иметь режим неявной адресации, то есть не от 0 , а некоторый условной базы. 
     
     В современных 64-битных процессорах от Intel или AMD осталось только 2 сегментных регистра - `FS`, `GS`, которые используются для сохранения базы к `ls`-данным для текущего потока, то есть, если у нас есть thread-локальная переменная, то вы можете адресовать эти данные по одному или тому же offset (пользуясь одним и тем же адресом), но используя разные сегментные регистры. Так как переключении контекстов, переключаются и значения сегментных регистров, то автоматически ваш код, работающий со thread-локальными данными, будет работать с разными данными в разных потоках. 

    - При этом нам необходимо __управлять ресурсом физической памяти__ - __выделять и освобождать__ память разными способами. Это ресурс ограниченный, поэтому нужно реализовать абстрактную удобную модель линейной памяти поверх физической памяти. 

    - Благодаря контролю над адресным пространством виртуальной памятью, можно предоставлять __больший объем физической__ памяти, чем существует на систему - обеспечить __своп технологию__ - вынесение неиспользуемых или давно не используемых блоков данных на диск и переиспользование физической страницы, которая использовалась для этого, для чего-то другого.

    - Очень важная функция виртуальной памяти -  __реализация и использование буферного кеша для файловой системы__. Из-за того, что виртуальная память позволяет делать достаточно сложные манипуляции, которые для самого процесса будут выглядеть как просто чтение или запись из того или иного адреса, возможно реализовывать файлы, отображаемые в память, под которыми лежит кеш буферов для взаимодействия с персистентным хранилищем - файловой системой.

    - Благодаря наличию этого контроля можно оптимизировать совместное использование ресурсов. Если посмотреть на современную программу под Windows/Linux, то список кодовых зависимостей у разных программ очень часто примерно одинаковый, то есть почти все программы зависят от `lib.c`, другие от графических библиотек. Наличие виртуальной памяти позволяет создавать удобную иллюзию, что одни и те же данные доступны в разных процессах, и это можно обеспечить достаточно дешево, используя одни и те же подлежащие физические страницы предоставлять вид, как-будто у процесса они свои. 

    В Linux есть такая уникальная страница, которая состоит из одних нулей и отображается практически во все процессы, например, если есть данные, которые инициализируются 0 операционной системой, то эта самая единственная страница замаплена в адресное пространство. Как только кто-то пытается записать туда какие-то данные в любое место страницы, случается fault (страница защищена за запись), и аллоцируется новая страница, куда реально пишутся данные - __COW (Copy On Write)__.


## Адресное пространство

![2.1]()

Тот самый разреженный массив слева - виртуальное адресное пространство, в котором сегментация на текст/данные/стек осталась логическая - есть некоторые переменные куски адресного пространства, которые посвящены использованию тех или иных фрагментов программы. 

Если посмотреть на физическую память, то отображение адресного пространства достаточно сложно, то есть то, какая конкретная страница используется для данного логического адреса, известно только ядру и потенциально может меняться. 

Более того, иногда такой страницы вообще может не быть, если произошел _своппинг - вынесение страницы, принадлежащей процессу на диск_. Тогда данная страница предоставлена какому-то другому процессу и в этот момент стрелка на рисунке указывает в никуда, точнее на страницу, любой доступ к который ведет к fault и к обращению в структуру ОС, которая говорит, где на диске хранятся данные соответствующие данному адресу. 


## Адресное пространство, трансляция

![2.2]()

Рассмотрим процесс трансляции виртуальных адресов. Логически говоря, у нас есть виртуальный адрес, который является индексом в этом самом условном адресном пространстве. Этот адрес делится на 2 части: некоторое количество нижних битов - _сдвиг страницы_, то есть, если мы что-то знаем про физический адрес то это то, что последние 12 битов физического адреса совпадают с последними 12 битами логического адреса. А вот верхняя часть адреса используется для осуществления трансляции адреса, которая производится способом различным для каждого адресного пространства. 

Поэтому, если мы хотим оттранслировать тот или иной виртуальный адрес, мы берем верхнюю часть этого адреса, консультируемся с таблицей страниц и на основании информации из этой страницы вычисляем, куда попадает данный адрес в физическую память, но возможны и следующе исходы: 
- адрес можно никуда не попадать
- исключение ОС, если не имее права обращаться к этому адресу
- трансляция не успешна, потому что ОС отправила своп нашей страницы. Однако ОС знает об этом факте, поэтому она поднимает страницу из свопа, замапливает куда-то, и трансляция после этого наконец получается. 


## Таблица трансляции

![3.1]()

Здесь указана таблица трансляции для 64-битного адресного пространства, потому что она более интересна и показывает концепции, которые нельзя увидеть на 32-битной системе. 

Биты 39 - 47 отвечают за сдвиг в _PGD_ - самая верхнеуровневая таблица. Структурно это дерево поиска, где каждая часть адреса отвечает за индексацию в своей компоненте. Мы использовали первую часть адреса (39 - 47) и нашли, используя базовый регистр таблицы страниц в качестве входа. Входом для данной трансляции является базовый адрес таблицы страниц для текущего процесса и в данном случае, сдвиг в этой таблице. 

Перейдя по вот этому адресу MMU.

Первый уровень - PGD (терминология Linux). Линуксовое ядро сильно абстрагирует функционирование MMU и из-за того, что оно импортированно много куда, эта логическая модель хорошо продумана для описывания многие процессоры. 

Далее PUDE - Page Upper Directory. Каждый элемент этой страницы - одна физическая страница, то есть на индексацию выделяется физическая страница. Таким же образом мы берем следующий кусок адреса (30 - 38) и индексируем в PUDE. Далее берем следующий кусочек адреса PMD. И наконец дошли до PT. PT - то место, которое говорит, где же на самом деле находится страница. Кроме этого, там хранится дополнительная информация о том, какие права доступа к этому адресу в рамках данной системы (одна и та же физическая страница может быть по-разному видна процессору, в зависимости от того, что сейчас записано в регистре CR3), то есть могут быть такие правила трансляции при которых одному процессу страничка кажется read-only и при попытке записи в нее происходит fault, а другому процессу она read-write.

Эта вариативность обеспечивается такой гибкой системой трансляции.

Биты с 63 - 48 никак не используются, ведь реальный размер виртуального адресного пространства, он меньше, чем 64 бита, из-за того, что, для того чтобы реализовать реальный lookup такой глубины (здесь мы реализовали 12 битов на сдвиг и 36 бита на остальное и того получилось 44 бита). Реальное адресуемое виртуальное адресное пространство чаще всего имеет ширину 46 бита (можно проверить, пытаясь менять значение в верхних частях адреса и смотреть, будут ли ломаться указатели или нет). 


## Устройство Page Directory Entry (PDE) x86

![3.2]()

Что собственно записано в одном из верхних уровней. Часть записи отвечает за адрес физической страницы, потому что этот адрес выровненный, то есть физический адрес начала страницы всегда выровнен, то есть всегда нижние 12 это нули, поэтому остальные части отвечают за то, каким образом можно общаться с тем, что мы данной страничкой адресуем. Мы можем, например, говорить, что это будет указатель не на 4 Кбайтную страницу, а на большую - для этого есть артрибут Page Size. Есть атрибут Accessed, который поддерживается соответственно автоматически MMU, при любом доступе через виртуальный адрес этот бит устанавливается в 1, то есть всегда можно знать, обращались ли к данной странице или нет. Это позволяет реализовывать алгоритмы вытеснения, наименее используемых страниц. Бит запрет кеширования, то есть любой доступ к этой странице должен происходить на прямую, а не храниться в кешах процессора. Это важно для ситуаций, когда данный виртуальный адрес отображает регистры того или иного устройства, например, видеокарт или сетевой карты. Тогда запись или чтение из того или иного адреса - та или иная команда оборудования, поэтому ее нельзя кешировать. Если эту команду послали - она должна случиться, оттого необходимо запрещать кеширование в этот момент. Write through - политика записи, позволяющая откладывать запись. Ubit - описание того, кто к этой страничке может обращаться, то есть является ли она собственностью ядра, тогда там записан 0 - supervisor страницы, либо 1 - то есть пользователь может к ней обращаться зи непривилегированных уровней. Rbit - описывает можно ли в эту страницу писать, если стоит - нельзя писать, можно только читать. P - - present - структура, описывающая то, а присутствует ли реально эта страница в физической памяти или нужно уже в этот момент трансляции осуществить page fault. 


## Устройство Page Table Entry (PTE) x86

![3.3]()

Похожая табличка и у PTE, разве, что используется G - global bit, говорящий, что данная страница присутствует и в одном и в другом адресном пространстве по одному и тому же адресу при переключении контекста, поэтому можно не инвалидировать в tlb и кешах, относящихся к данной странице (исключительно для оптимизации). 

Типичная ситуация в процессорах, что некоторые биты остаются под будущее расширение, то есть он в данный момент является 0, а в процессорах (AMD - MBZ- Must Be Zero) типичное поведение такое - есть некоторое старое дефолтное поведение, при добавлении в процессор новой фичи можно активировать новое поведение, а старые программы обязаны писать туда 0, поскольку о новом поведении не знают.


